#!/usr/bin/python

import sys, getopt, time, urllib2, re, argparse, os

#TODO:
#alt tags?
#check version, link to update if not up to date

localcp = False
dailydir = False
stripdir = False
outfile = "index.html"
UserAgent = "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Ubuntu Chromium/37.0.2062.120 Chrome/37.0.2062.120 Safari/537.36"
timestamp = None

# minimum size to consider a valid image download,
# extension type test will look at up to 8 bytes
MINSIZE = 512


def classType(data, cl):
	if (not cl):
		return "can't find class %s for strip %s<br /><br />\n\n" %(data.get('useclass'), data.get('strip', str(data)))
	newstrip = {}
	#copy data from cl to newstrip
	newstrip.update(cl)
	#copy data from strip to newstrip
	newstrip.update(data)
	return stripType(newstrip)


def getArtist(data):
	if ('artist' in data):
		return ' by %s' %(data['artist'])
	else:
		return ''

def getTitle(data):
	txt = ''
	if (data.get('homepage')):
		txt +='<b><a href=\"%s\">%s</a></b>' %(stringsubs(data.get('homepage')), data.get('name'))
	else:
		txt += '<b>%s</b>' %(data.get('name'))
	return txt



def httpRequest(url, referer):
	request = urllib2.Request(url)
	request.add_header("User-Agent", UserAgent)
	request.add_header("Accept", "text/html")
	request.add_header('Pragma', 'no-cache')
	request.add_header('Cache-Control', 'no-cache')
	request.add_header('Accept-Language', 'en-US,en;q=0.8')
	if referer:
		request.add_header("Referer", referer)
	data = ''
	errtxt = None
	try:
		resp = urllib2.urlopen(request)
		data = resp.read()
	except urllib2.HTTPError as err:
		errtxt = 'HTTP %s error trying to access %s: %s' %(err.code, url, err.reason)
	except Exception as err:
		errtxt = 'Unknown error occured trying to access %s: %s' %(url, err)
	return data,errtxt


def dirNfileName(name, theday):
	date = time.strftime('%Y.%m.%d', time.localtime(theday))
	if dailydir:
		dname = date
		fname = name
	elif stripdir:
		dname = name
		fname = date
	else:
		dname = 'tmp'
		fname = '%s-%s' % (name, date)
	return dname, fname

def duplicateOfYesterday(imgtoday, name, ext):
	dname, fname = dirNfileName(name, timestamp - 86400)
	pname = "%s/%s%s" % (dname, fname, ext)
	try:
		with open(pname, 'rb') as f:
			imgyesterday = f.read()
	except (OSError, IOError):
		imgyesterday = ''
	return len(imgtoday) == len(imgyesterday) and imgtoday == imgyesterday

def imageLocalCp(name, url, referer):
	dname, fname = dirNfileName(name, timestamp)
	for ext in (".gif", ".jpg", ".png", ".bmp", ""):
		pname = "%s/%s%s" % (dname, fname, ext)
		if os.path.exists(pname):
			return pname, ""

	pname = None
	imgdata, errtxt = httpRequest(url, referer)

	if imgdata and len(imgdata) < MINSIZE:
		errtxt = 'Retrieved image was too small'

	elif imgdata:
		ext = \
			".gif" if imgdata[0:6] == "GIF87a" or imgdata[0:6] == "GIF89a" else \
			".jpg" if imgdata[0:2] == "\xff\xd8" else \
			".png" if imgdata[0:8] == "\x89PNG\r\n\x1A\n" else \
			".bmp" if imgdata[0:2] == "BM" else \
			""
		if duplicateOfYesterday(imgdata, name, ext):
			errtxt = 'Retrieved image was the same as yesterday'
		else:
			try:
				os.mkdir(dname)
			except OSError:
				pass
			pname = "%s/%s%s" % (dname, fname, ext)
			with open(pname, 'wb') as f:
				f.write(imgdata)

	return pname,errtxt


def replaceVars(data):
	strip = {}
	# define variables, the implicit ones (e.g. homepage)
	variables = dict({('$'+key,val) for key,val in data.items() if not key.startswith('$')})
	# and the explicit vars
	variables.update({(key,val) for key,val in data.items() if key.startswith('$')})
	# expand variable references
	for key,val in data.items():
		if key.startswith('$'):
			continue
		while '$' in val:
			for vari,valu in variables.items():
				val = val.replace(vari, valu)
		strip[key] = val
	#print data,variables,strip
	return strip


def stripType(stripdef):
	data = replaceVars(stripdef)
	image = ""
	errtxt = ""
	html = "%s%s<br />\n" % (getTitle(data), getArtist(data))
	if (data['type'].startswith('search')):
		url = stringsubs(data.get('searchpage') or data.get('homepage'))
		page, errtxt = httpRequest(url, data.get('referer'))
		if page:
			pattern = re.compile(data.get('searchpattern'))
			m = pattern.search(page)
			if (m):
				image = "%s%s" % (data.get('baseurl') or "", m.group())
			else:
				html += 'Could not find regex in page %s' %(url)
		else:
			html += 'Search page failed: %s' % errtxt
			errtxt = ""
	elif (data['type'].startswith('generate')):
		image = stringsubs(data['imageurl'])
	else:
		html += "Say what? Couldn't understand the strip type"
	#print "Local:",localcp,stripdir,dailydir
	if image and localcp:
		image, errtxt = imageLocalCp(data.get('name'), image, data.get('referer'))
	return "%s<img src=\"%s\" /><br />\n\n" % (html, image.replace(" ","%20")) if image \
		else "%s%s<br />\n\n" % (html, errtxt)



def stringsubs(image):
	ltm = time.localtime(timestamp)
	image = image.replace("%Y", time.strftime("%Y", ltm))
	image = image.replace("%y", time.strftime("%y", ltm))
	image = image.replace("%m", time.strftime("%m", ltm))
	image = image.replace("%d", time.strftime("%d", ltm))
	return image


def getStrips(toget, strips):
	with open(outfile, "a") as myfile:
		for s in toget:
			try:
				strip = strips[s]
			except KeyError:
				html = 'Could not find strip %s in strips.def file' %(s)
				print html
				html += '<br />\n\n'
			else:
				if ('useclass' in strip):
					html = classType(strip, strips.get(strip['useclass']))
				elif ('type' in strip):
					html = stripType(strip)
				else:
					html = "could not understand strip definition.<br />\n\n"
			myfile.write(html)


def init(deffile):
	strips = {}
	with open(deffile, "r") as defs:
		strip = {}
		title = ''
		for line in defs:
			line = line.strip()
			if (not line):
				continue
			if (line.startswith('#')):
				continue
			if (line.startswith("end")):
				strips[title] = strip
				strip = {}
				title=''
				continue
			if (line.startswith("strip")):
				id, name = line.split(" ", 1)
				if (strips.get(name)):
					print 'found a duplicate for %s in def file. Going with first one.' %(name)
					continue
				title = name
				strip['strip'] = name
				#print name
			elif (line.startswith("class")):
				id, call = line.split(" ", 1)
				title = call
			else:
				prop, val = line.split(" ", 1)
				strip[prop] = val
	return strips



def printFooter():
	with open(outfile, "a") as myfile:
		myfile.write("<br /><br />\ngenerated at %s<br />\n" % time.asctime(time.localtime(timestamp)))
		myfile.write("powered by <a href=\"https://github.com/bachrach44/pydailystrips\">py daily strips</a>\n</body></html>\n")


def printHeader():
	with open(outfile, "w") as myfile:
		myfile.write("<html><head><title>Python Daily Strips</title></head>\n<body><b><font size=4><center>Python Daily Strips for %s</center></font></b><br /><br />\n\n" %(time.strftime("%A, %b %d %Y", time.localtime(timestamp))))



def loadFromFile(filename):
	with open (filename, "r") as myfile:
		text = myfile.read()
	return text.split()


def main(argv):
	global outfile, localcp, dailydir, stripdir, timestamp
	parser = argparse.ArgumentParser()
	parser.add_argument("-o", "--output", help="output file to write to")
	parser.add_argument("-i", "--input", help="input file to read from")
	parser.add_argument("-l", "--local", help="keep a copy (download) each strip", action="store_true")
	parser.add_argument("-d", "--dailydir", help="create a directory each day", action="store_true")
	parser.add_argument("--stripdir", help="create a directory for each strip", action="store_true")
	parser.add_argument("-v", "--version", help="print version and exit", action="store_true")
	parser.add_argument("--defs", help="Path to the strip definition file")
	parser.add_argument("strips", metavar='strips', nargs='*', help='strips to load, separated by spaces')
	args = parser.parse_args()
	if (args.version):
		print "Are you kidding? This isn't even beta. What are you even doing looking at this?"
		exit(0)
	outfile = args.output or outfile
	localcp = args.local
	dailydir = args.dailydir
	stripdir = args.stripdir

	#load classes from def file
	strips = init(args.defs or 'strips.def')

	# use a consistent timestamp for the entire execution
	timestamp = time.time()

	toget = loadFromFile(args.input) if (args.input) else args.strips

	printHeader()
	getStrips(toget, strips)
	printFooter()




if __name__ == '__main__':
	main(sys.argv)

#other options I might consider supporting (from dailystrips)
#   quiet|q  verbose   local|l   noindex   archive|a   dailydir|d   stripdir   save|s
#   nostale   date=s   new|n   nopersonal   basedir=s   list   proxy=s
#   proxyauth=s   noenvproxy   nospaces   useragent=s   random   nosystem   stripnav
#   nosymlinks   titles=s   retries=s   clean=s   updates=s   noupdates
#
#Options supported by dailystrips that I have no plan on supporting
#avantgo, lite





